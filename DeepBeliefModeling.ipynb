{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Deep Belief Modeling\n",
    "Project for SI course"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"resources/data.csv\", sep=\"\\t\")\n",
    "# maybe add test data in future"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Input data visualisation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = df_train[\"label\"].value_counts()\n",
    "x.plot(kind=\"bar\", color=[\"r\", \"b\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Text pre-processing for classification"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# nie dziala\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return \"\".join([c for c in text if c not in string.punctuation and c != \"’\" and c != \"—\"])\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    return text.replace(r'[^A-Za-z0-9 ]+', '')\n",
    "\n",
    "def remove_numbers(text):\n",
    "    return re.sub('\\d+', '', text)\n",
    "\n",
    "def tokenization(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return [w for w in text if w not in stop_words]\n",
    "\n",
    "def lemmatizer(text):\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    return [wordnet_lemmatizer.lemmatize(w) for w in text]\n",
    "\n",
    "def text_preprocessing(text):\n",
    "    text = remove_punctuation(text)\n",
    "    text = remove_special_characters(text)\n",
    "    text = remove_numbers(text)\n",
    "    text = text.lower()\n",
    "    text = tokenization(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = lemmatizer(text)\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/54398984\n",
    "# prawie dziala\n",
    "\n",
    "from nltk import RegexpTokenizer\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(sentence):\n",
    "    sentence = str(sentence)\n",
    "    sentence = sentence.lower()\n",
    "    sentence = sentence.replace('{html}',\"\")\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', sentence)\n",
    "    rem_url = re.sub(r'http\\S+', '',cleantext)\n",
    "    rem_num = re.sub('\\d+', '', rem_url)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(rem_num)\n",
    "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
    "    lemma_words = [wordnet_lemmatizer.lemmatize(w) for w in filtered_words]\n",
    "    return lemma_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    It's been quite a week. I've been in the media...\n",
      "1    This week has been eye-opening. Even for me --...\n",
      "2    Yes, it's true. I beat COVID-19 in 48 hours wi...\n",
      "3    The COVID-19 vaccines appear to be causing a g...\n",
      "4    Back in the 1980s, I was a Columbia University...\n",
      "5    So you got the vaccine because they told you t...\n",
      "6    I Am A Living Proof That COVID-19 Is Fake This...\n",
      "7    I have a PhD in virology and immunology. I’m a...\n",
      "8    How do you convince the world’s population to ...\n",
      "9    Take 15 minutes and listen to this interview w...\n",
      "Name: data, dtype: object\n",
      "0    [quite, week, ive, medium, business, decade, i...\n",
      "1    [week, eyeopening, even, im, guy, warned, year...\n",
      "2    [yes, true, beat, covid, hour, ivermectin, get...\n",
      "3    [covid, vaccine, appear, causing, global, heal...\n",
      "4    [back, columbia, university, student, learning...\n",
      "5    [got, vaccine, told, get, forced, get, joe, bi...\n",
      "6    [living, proof, covid, fake, unfiltered, take,...\n",
      "7    [phd, virology, immunology, im, clinical, lab,...\n",
      "8    [convince, world, population, take, unproven, ...\n",
      "9    [take, minute, listen, interview, hospital, nu...\n",
      "Name: data, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_train[\"data\"].head(10))\n",
    "print(df_train[\"data\"].apply(text_preprocessing).head(10))\n",
    "\n",
    "preprocessed_data = df_train[\"data\"].apply(text_preprocessing)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature selection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TF-IDF Vectorizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['________________________________________________________________________'\n",
      " 'aabduzrw' 'aaby' ... 'zoster' 'zuckerberg' 'zurich']\n",
      "['________________________________________________________________________'\n",
      " 'aabduzrw' 'aaby' ... 'zoster' 'zuckerberg' 'zurich']\n",
      "Count vectorizer\n",
      "     ________________________________________________________________________  \\\n",
      "0                                                    0                          \n",
      "1                                                    0                          \n",
      "2                                                    0                          \n",
      "3                                                    0                          \n",
      "4                                                    0                          \n",
      "..                                                 ...                          \n",
      "123                                                  0                          \n",
      "124                                                  0                          \n",
      "125                                                  0                          \n",
      "126                                                  0                          \n",
      "127                                                  0                          \n",
      "\n",
      "     aabduzrw  aaby  aaho  aamcnews  aaron  aarp  abbott  abby  abc  ...  \\\n",
      "0           0     0     0         0      0     0       0     0    0  ...   \n",
      "1           0     0     0         0      0     0       0     0    0  ...   \n",
      "2           0     0     0         0      1     0       0     0    0  ...   \n",
      "3           0     0     0         0      0     0       0     0    0  ...   \n",
      "4           0     0     0         0      0     0       0     0    0  ...   \n",
      "..        ...   ...   ...       ...    ...   ...     ...   ...  ...  ...   \n",
      "123         0     0     0         0      1     0       0     0    0  ...   \n",
      "124         0     0     0         0      0     0       0     0    0  ...   \n",
      "125         0     0     0         0      0     0       0     0    0  ...   \n",
      "126         0     0     0         0      0     0       1     0    0  ...   \n",
      "127         0     0     0         0      0     0       0     0    0  ...   \n",
      "\n",
      "     zelenko  zero  zev  zika  zinc  zombie  zoom  zoster  zuckerberg  zurich  \n",
      "0          0     1    0     0     0       0     0       0           0       0  \n",
      "1          0     0    0     0     0       0     0       0           0       0  \n",
      "2          0     0    0     0     1       0     1       0           0       0  \n",
      "3          0     0    0     0     0       0     0       0           0       0  \n",
      "4          0     0    0     0     0       0     0       0           0       0  \n",
      "..       ...   ...  ...   ...   ...     ...   ...     ...         ...     ...  \n",
      "123        0     0    0     0     0       0     0       0           0       0  \n",
      "124        0     0    0     0     0       0     0       0           0       0  \n",
      "125        0     0    0     0     0       0     0       0           0       0  \n",
      "126        0     2    0     0     0       0     0       0           0       0  \n",
      "127        0     0    0     0     0       0     0       0           0       0  \n",
      "\n",
      "[128 rows x 7842 columns]\n",
      "Tf-idf vectorizer\n",
      "     ________________________________________________________________________  \\\n",
      "0                                                  0.0                          \n",
      "1                                                  0.0                          \n",
      "2                                                  0.0                          \n",
      "3                                                  0.0                          \n",
      "4                                                  0.0                          \n",
      "..                                                 ...                          \n",
      "123                                                0.0                          \n",
      "124                                                0.0                          \n",
      "125                                                0.0                          \n",
      "126                                                0.0                          \n",
      "127                                                0.0                          \n",
      "\n",
      "     aabduzrw  aaby  aaho  aamcnews     aaron  aarp    abbott  abby  abc  ...  \\\n",
      "0         0.0   0.0   0.0       0.0  0.000000   0.0  0.000000   0.0  0.0  ...   \n",
      "1         0.0   0.0   0.0       0.0  0.000000   0.0  0.000000   0.0  0.0  ...   \n",
      "2         0.0   0.0   0.0       0.0  0.032700   0.0  0.000000   0.0  0.0  ...   \n",
      "3         0.0   0.0   0.0       0.0  0.000000   0.0  0.000000   0.0  0.0  ...   \n",
      "4         0.0   0.0   0.0       0.0  0.000000   0.0  0.000000   0.0  0.0  ...   \n",
      "..        ...   ...   ...       ...       ...   ...       ...   ...  ...  ...   \n",
      "123       0.0   0.0   0.0       0.0  0.054671   0.0  0.000000   0.0  0.0  ...   \n",
      "124       0.0   0.0   0.0       0.0  0.000000   0.0  0.000000   0.0  0.0  ...   \n",
      "125       0.0   0.0   0.0       0.0  0.000000   0.0  0.000000   0.0  0.0  ...   \n",
      "126       0.0   0.0   0.0       0.0  0.000000   0.0  0.037119   0.0  0.0  ...   \n",
      "127       0.0   0.0   0.0       0.0  0.000000   0.0  0.000000   0.0  0.0  ...   \n",
      "\n",
      "     zelenko      zero  zev  zika      zinc  zombie     zoom  zoster  \\\n",
      "0        0.0  0.041564  0.0   0.0  0.000000     0.0  0.00000     0.0   \n",
      "1        0.0  0.000000  0.0   0.0  0.000000     0.0  0.00000     0.0   \n",
      "2        0.0  0.000000  0.0   0.0  0.034417     0.0  0.03663     0.0   \n",
      "3        0.0  0.000000  0.0   0.0  0.000000     0.0  0.00000     0.0   \n",
      "4        0.0  0.000000  0.0   0.0  0.000000     0.0  0.00000     0.0   \n",
      "..       ...       ...  ...   ...       ...     ...      ...     ...   \n",
      "123      0.0  0.000000  0.0   0.0  0.000000     0.0  0.00000     0.0   \n",
      "124      0.0  0.000000  0.0   0.0  0.000000     0.0  0.00000     0.0   \n",
      "125      0.0  0.000000  0.0   0.0  0.000000     0.0  0.00000     0.0   \n",
      "126      0.0  0.048493  0.0   0.0  0.000000     0.0  0.00000     0.0   \n",
      "127      0.0  0.000000  0.0   0.0  0.000000     0.0  0.00000     0.0   \n",
      "\n",
      "     zuckerberg  zurich  \n",
      "0           0.0     0.0  \n",
      "1           0.0     0.0  \n",
      "2           0.0     0.0  \n",
      "3           0.0     0.0  \n",
      "4           0.0     0.0  \n",
      "..          ...     ...  \n",
      "123         0.0     0.0  \n",
      "124         0.0     0.0  \n",
      "125         0.0     0.0  \n",
      "126         0.0     0.0  \n",
      "127         0.0     0.0  \n",
      "\n",
      "[128 rows x 7842 columns]\n"
     ]
    }
   ],
   "source": [
    "# https://medium.com/@cmukesh8688/tf-idf-vectorizer-scikit-learn-dbc0244a911a\n",
    "\n",
    "count_vectorizer = CountVectorizer(tokenizer=preprocess)\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=preprocess)\n",
    "\n",
    "count_wm = count_vectorizer.fit_transform(df_train[\"data\"])\n",
    "tfidf_wm = tfidf_vectorizer.fit_transform(df_train[\"data\"])\n",
    "\n",
    "count_tokens = count_vectorizer.get_feature_names_out()\n",
    "tfidf_tokens = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "print(count_tokens)\n",
    "print(tfidf_tokens)\n",
    "\n",
    "df_count_vect = pd.DataFrame(data=count_wm.toarray(), columns=count_tokens)\n",
    "df_tfidf_vect = pd.DataFrame(data=tfidf_wm.toarray(), columns=tfidf_tokens)\n",
    "\n",
    "print(\"Count vectorizer\")\n",
    "print(df_count_vect)\n",
    "print(\"Tf-idf vectorizer\")\n",
    "print(df_tfidf_vect)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}